<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>My Personal Website</title>

    <meta name="author" content="Yizhou Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Favicon and CSS are optional; remove or modify these as you like. -->
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <style>
      /* (Optional) Some minimal inline CSS to mimic original styling */
      body {
        font-family: sans-serif;
        margin: 0;
        padding: 0;
      }
      .name {
        font-size: 1.8em;
        font-weight: bold;
      }
      .papertitle {
        font-weight: bold;
      }
      .one {
        position: relative;
      }
      .two {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        opacity: 0;
        transition: opacity 0.3s ease;
      }
    </style>
  </head>

  <body>
    <!-- Top-Level Container -->
    <table style="width:100%;max-width:800px;margin:auto;border:0; border-spacing:0; padding:0;">
      <tbody>
        <!-- Header row -->
        <tr>
          <td>
            <table style="width:100%;border:0; padding:0; border-spacing:0;">
              <tbody>
                <tr>
                  <!-- Left side: Name and introduction -->
                  <td style="padding:2.5%;width:72%;vertical-align:middle;">
                    <p class="name" style="text-align: center;">Yizhou Chen</p>
                    <p>
                     I am currently a Ph.D. candidate in robotics at the University of Michigan. 
                     I am a member of <a href="https://www.roahmlab.com/">ROAHM Lab</a> supervised by Prof. Ram Vasudevan.  
                     My current research interests include the perception, modeling, and planning of deformable objects.
                     My dream demo is to make wireharness assembly fully autonomous.
                     <br />
                     <br />
                      Previously, I worked at <a href="https://www.mmintlab.com/">MMint Lab</a>, supervised by Prof. Nima Fazeli, researching visuo-tactile representation for robotic manipulation.                    </p>
                    <p style="text-align:center">
                      <a href="mailto:yizhouch@umich.edu">Email</a> &nbsp;/&nbsp;
                      <a href="data/Yizhou_Chen_CV.pdf">CV</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=F81ZmWMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                      <a href="https://github.com/yich7045">Github</a>
                    </p>
                  </td>
                  <!-- Right side: Photo -->
                  <td style="padding:2.5%;width:28%;max-width:100%;">
                    <a href="images/YizhouChen.jpg">
                      <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 100%;" 
                           alt="Yizhou Chen" src="images/YizhouChen.jpg">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Research Section -->
            <table style="width:100%;border:0; border-spacing:0; padding:0;">
              <tbody>
                <tr>
                  <td style="padding:16px;width:100%;vertical-align:middle">
                    <h2>Research Projects</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <!-- SINGLE PROJECT: "DEFT" -->
            <table style="width:100%;border:0; border-spacing:0;">
                <tbody>
                  <tr bgcolor="#ffffd0">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <!-- Just a single image, no hover effect. -->
                      <img src="images/Insertion.png" width="260" alt="Thread Insertion">
                    </td>
              
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2502.10647">
                        <span class="papertitle">DEFT: Differentiable Branched Discrete Elastic Rods for Modeling Furcated DLOs in Real-Time</span>
                      </a>
                      <br><strong>Yizhou Chen</strong>, Xiaoyue Wu, Yeheng Zong, Anran Li, Yuzhen Chen, Julie Wu, Bohao Zhang, Ram Vasudevan
                      <br><em>arXiv</em>, 2025
                      <br>
                      <a href="https://arxiv.org/abs/2502.15037">arXiv</a> /
                      <a href="https://roahmlab.github.io/DEFT/">project website</a>
                      <p></p>
                      <p>
                        This paper presents Differentiable discrete branched Elastic rods for modeling Furcated DLOs in real-Time (DEFT), a novel framework that combines a differentiable physics-based model with a learning framework to: 
                        1) accurately model branched deformable linear objects (BDLOs) dynamics, including dynamic propagation at junction points and grasping in the middle of a BDLO, 
                        2) achieve efficient computation for real-time inference, 
                        and 3) enable planning to demonstrate dexterous BDLO manipulation.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
              <!-- SINGLE PROJECT: "DEFT" -->
            <table style="width:100%;border:0; border-spacing:0;">
                <tbody>
                  <tr bgcolor="#ffffd0">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <!-- Just a single image, no hover effect. -->
                      <img src="images/DEFORM.png" width="260" alt="Thread Insertion">
                    </td>
              
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2502.10647">
                        <span class="papertitle">Differentiable Discrete Elastic Rods for Real-Time Modeling of Deformable Linear Objects</span>
                      </a>
                      <br><strong>Yizhou Chen</strong>, Yiting Zhang, Zachary Brei, Tiancheng Zhang, Yuzhen Chen, Julie Wu, Ram Vasudevan
                      <br><em>CoRL</em>, 2024
                      <br>
                      <a href="https://arxiv.org/abs/2406.05931">arXiv</a> /
                      <a href="https://roahmlab.github.io/DEFORM/">project website</a>
                      <p></p>
                      <p>
                      This paper proposes differentiable Discrete Elastic Rods For deformable linear Objects with Real-time Modeling (DEFORM), a novel framework that combines a differentiable physics-based model with a learning framework to model deformable linear objects (DLOs) accurately and in real-time. 
                        To further demonstrate the utility of DEFORM, this paper integrates it into a perception pipeline and illustrates its superior performance when compared to the state-of-the-art methods while tracking a DLO even in the presence of occlusions. 
                        Finally, this paper illustrates the superior performance of DEFORM when compared to state-of-the-art methods when it is applied to perform autonomous planning and control of DLOs.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>

              <table style="width:100%;border:0; border-spacing:0;">
                <tbody>
                  <tr bgcolor="#ffffd0">
                    <td style="padding:16px;width:20%;vertical-align:middle">
                      <!-- Just a single image, no hover effect. -->
                      <img src="images/VTT.png" width="260" alt="Thread Insertion">
                    </td>
              
                    <td style="padding:8px;width:80%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2502.10647">
                        <span class="papertitle">Differentiable Discrete Elastic Rods for Real-Time Modeling of Deformable Linear Objects</span>
                      </a>
                      <br><strong>Yizhou Chen</strong>, Yiting Zhang, Zachary Brei, Tiancheng Zhang, Yuzhen Chen, Julie Wu, Ram Vasudevan
                      <br><em>CoRL</em>, 2022
                      <br>
                      <a href="https://arxiv.org/abs/2210.00121">arXiv</a> /
                      <a href="https://www.mmintlab.com/research/vtt/">project website</a>
                      <p></p>
                      <p>
                      Learning representations in the joint domain of vision and touch can improve manipulation dexterity, robustness, and sample-complexity by exploiting mutual information and complementary cues. 
                        Here, we present Visuo-Tactile Transformers (VTTs), a novel multimodal representation learning approach suited for model-based reinforcement learning and planning. 
                        Our approach extends the Visual Transformer to handle visuo-tactile feedback. Specifically, VTT uses tactile feedback together with self and cross-modal attention to build latent heatmap representations that focus attention on important task features in the visual domain. 
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
            
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
